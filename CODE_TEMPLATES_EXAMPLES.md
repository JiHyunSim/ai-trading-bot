# ì½”ë“œ í…œí”Œë¦¿ ë° êµ¬í˜„ ì˜ˆì‹œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” OKX ì‹¤ì‹œê°„ ìº”ë“¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„ì„ ìœ„í•œ ì™„ì „í•œ ì½”ë“œ í…œí”Œë¦¿, ì„¤ì • íŒŒì¼, êµ¬í˜„ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. Claude Codeë¥¼ í†µí•´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ ì½”ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
okx-trading-system/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ gateway/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ database.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â””â”€â”€ redis_client.py
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”œâ”€â”€ collector/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ handlers.py
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚       â””â”€â”€ reconnect.py
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â””â”€â”€ processor/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ processors/
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚       â”‚   â”‚   â””â”€â”€ validator.py
â”‚       â”‚   â”œâ”€â”€ core/
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ config.py
â”‚       â”‚   â”‚   â””â”€â”€ database.py
â”‚       â”‚   â””â”€â”€ utils/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â””â”€â”€ metrics.py
â”‚       â””â”€â”€ tests/
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ init/
â”‚   â”‚   â”œâ”€â”€ 01_extensions.sql
â”‚   â”‚   â”œâ”€â”€ 02_schema.sql
â”‚   â”‚   â”œâ”€â”€ 03_functions.sql
â”‚   â”‚   â””â”€â”€ 04_initial_data.sql
â”‚   â””â”€â”€ migrations/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ postgresql.conf
â”‚   â”œâ”€â”€ redis.conf
â”‚   â””â”€â”€ logging.conf
â”œâ”€â”€ k8s/
â”œâ”€â”€ monitoring/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ scripts/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ í•µì‹¬ ì„œë¹„ìŠ¤ êµ¬í˜„

### 1. Gateway Service êµ¬í˜„

#### requirements.txt
```txt
# Gateway Service ì˜ì¡´ì„±
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
asyncpg==0.29.0
redis[hiredis]==5.0.1
prometheus-client==0.19.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0
structlog==23.2.0
```

#### app/core/config.py
```python
# services/gateway/app/core/config.py
from pydantic_settings import BaseSettings
from typing import Optional, List
import os

class Settings(BaseSettings):
    # ì•± ì„¤ì •
    app_name: str = "OKX Gateway API"
    app_version: str = "1.0.0"
    environment: str = "development"
    debug: bool = False
    
    # ì„œë²„ ì„¤ì •
    host: str = "0.0.0.0"
    port: int = 8000
    workers: int = 1
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    db_host: str = "localhost"
    db_port: int = 5432
    db_name: str = "okx_trading_data"
    db_user: str = "postgres"
    db_password: str = "password"
    db_pool_size: int = 20
    db_pool_min_size: int = 5
    
    # Redis ì„¤ì •
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    redis_password: Optional[str] = None
    redis_max_connections: int = 100
    
    # API ì„¤ì •
    api_v1_prefix: str = "/api/v1"
    cors_origins: List[str] = ["*"]
    cors_methods: List[str] = ["*"]
    cors_headers: List[str] = ["*"]
    
    # ì¸ì¦ ì„¤ì • (í–¥í›„ ì‚¬ìš©)
    secret_key: str = "your-secret-key-here"
    algorithm: str = "HS256"
    access_token_expire_minutes: int = 30
    
    # ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_format: str = "json"
    
    # ë©”íŠ¸ë¦­ ì„¤ì •
    metrics_enabled: bool = True
    metrics_port: int = 8080
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„¤ì •
    max_symbols_per_subscription: int = 50
    max_timeframes_per_subscription: int = 10
    default_query_limit: int = 100
    max_query_limit: int = 1000
    
    @property
    def database_url(self) -> str:
        return f"postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{self.db_name}"
    
    @property
    def redis_url(self) -> str:
        if self.redis_password:
            return f"redis://:{self.redis_password}@{self.redis_host}:{self.redis_port}/{self.redis_db}"
        return f"redis://{self.redis_host}:{self.redis_port}/{self.redis_db}"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = Settings()
```

#### app/core/database.py
```python
# services/gateway/app/core/database.py
import asyncpg
from typing import Optional
import logging
from .config import settings

logger = logging.getLogger(__name__)

class DatabaseManager:
    def __init__(self):
        self.pool: Optional[asyncpg.Pool] = None
    
    async def initialize(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™”"""
        try:
            self.pool = await asyncpg.create_pool(
                host=settings.db_host,
                port=settings.db_port,
                database=settings.db_name,
                user=settings.db_user,
                password=settings.db_password,
                min_size=settings.db_pool_min_size,
                max_size=settings.db_pool_size,
                command_timeout=60,
                server_settings={
                    'application_name': 'okx_gateway',
                    'timezone': 'UTC',
                }
            )
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì¢…ë£Œ"""
        if self.pool:
            await self.pool.close()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    async def health_check(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            async with self.pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            return True
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def get_symbols(self, active_only: bool = True):
        """í™œì„± ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ"""
        query = """
            SELECT s.id, s.symbol, s.base_currency, s.quote_currency, 
                   s.instrument_type, s.status
            FROM symbols s
            WHERE ($1::boolean = false OR s.status = 'ACTIVE')
            ORDER BY s.symbol
        """
        async with self.pool.acquire() as conn:
            return await conn.fetch(query, active_only)
    
    async def get_timeframes(self, active_only: bool = True):
        """í™œì„± ì‹œê°„í”„ë ˆì„ ëª©ë¡ ì¡°íšŒ"""
        query = """
            SELECT tf.id, tf.name, tf.display_name, tf.seconds, tf.sort_order
            FROM timeframes tf
            WHERE ($1::boolean = false OR tf.is_active = true)
            ORDER BY tf.sort_order
        """
        async with self.pool.acquire() as conn:
            return await conn.fetch(query, active_only)
    
    async def get_candle_data(self, symbol: str, timeframe: str, 
                             limit: int = 100, start_time=None, end_time=None):
        """ìº”ë“¤ìŠ¤í‹± ë°ì´í„° ì¡°íšŒ"""
        query = """
            SELECT cd.timestamp, cd.open_price, cd.high_price, cd.low_price,
                   cd.close_price, cd.volume, cd.volume_currency, cd.confirm,
                   cd.trade_count, cd.vwap
            FROM candlestick_data cd
            JOIN symbols s ON cd.symbol_id = s.id
            JOIN timeframes tf ON cd.timeframe_id = tf.id
            WHERE s.symbol = $1 AND tf.name = $2
            AND ($3::timestamp IS NULL OR cd.timestamp >= $3)
            AND ($4::timestamp IS NULL OR cd.timestamp <= $4)
            ORDER BY cd.timestamp DESC
            LIMIT $5
        """
        async with self.pool.acquire() as conn:
            return await conn.fetch(query, symbol, timeframe, start_time, end_time, limit)

# ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
db_manager = DatabaseManager()
```

#### app/utils/redis_client.py
```python
# services/gateway/app/utils/redis_client.py
import redis.asyncio as redis
import json
import logging
from typing import Optional, Dict, Any, List
from ..core.config import settings

logger = logging.getLogger(__name__)

class RedisManager:
    def __init__(self):
        self.redis: Optional[redis.Redis] = None
    
    async def initialize(self):
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        try:
            self.redis = await redis.from_url(
                settings.redis_url,
                max_connections=settings.redis_max_connections,
                decode_responses=True,
                health_check_interval=30
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.redis.ping()
            logger.info("Redis ì—°ê²°ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"Redis ì—°ê²° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def close(self):
        """Redis ì—°ê²° ì¢…ë£Œ"""
        if self.redis:
            await self.redis.close()
            logger.info("Redis ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    async def health_check(self) -> bool:
        """Redis ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            await self.redis.ping()
            return True
        except Exception as e:
            logger.error(f"Redis í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def publish_subscription(self, symbol: str, config: Dict[str, Any]):
        """êµ¬ë… ìš”ì²­ì„ ì»¬ë ‰í„°ì— ë°œí–‰"""
        try:
            channel = f"collector:{symbol}"
            message = json.dumps(config)
            await self.redis.publish(channel, message)
            logger.info(f"êµ¬ë… ìš”ì²­ ë°œí–‰: {symbol}")
        except Exception as e:
            logger.error(f"êµ¬ë… ìš”ì²­ ë°œí–‰ ì‹¤íŒ¨ - {symbol}: {e}")
            raise
    
    async def set_subscription(self, symbol: str, config: Dict[str, Any], ttl: int = 3600):
        """êµ¬ë… ì„¤ì • ì €ì¥"""
        try:
            key = f"subscription:{symbol}"
            value = json.dumps(config)
            await self.redis.setex(key, ttl, value)
        except Exception as e:
            logger.error(f"êµ¬ë… ì„¤ì • ì €ì¥ ì‹¤íŒ¨ - {symbol}: {e}")
            raise
    
    async def get_subscription(self, symbol: str) -> Optional[Dict[str, Any]]:
        """êµ¬ë… ì„¤ì • ì¡°íšŒ"""
        try:
            key = f"subscription:{symbol}"
            value = await self.redis.get(key)
            if value:
                return json.loads(value)
            return None
        except Exception as e:
            logger.error(f"êµ¬ë… ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨ - {symbol}: {e}")
            return None
    
    async def delete_subscription(self, symbol: str):
        """êµ¬ë… ì„¤ì • ì‚­ì œ"""
        try:
            key = f"subscription:{symbol}"
            await self.redis.delete(key)
            # êµ¬ë… ì¤‘ì§€ ì‹ í˜¸ ë°œì†¡
            stop_config = {"action": "unsubscribe", "symbol": symbol}
            await self.publish_subscription(symbol, stop_config)
        except Exception as e:
            logger.error(f"êµ¬ë… ì„¤ì • ì‚­ì œ ì‹¤íŒ¨ - {symbol}: {e}")
            raise
    
    async def get_all_subscriptions(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  êµ¬ë… ì„¤ì • ì¡°íšŒ"""
        try:
            pattern = "subscription:*"
            keys = await self.redis.keys(pattern)
            
            subscriptions = []
            for key in keys:
                symbol = key.split(":", 1)[1]
                value = await self.redis.get(key)
                if value:
                    config = json.loads(value)
                    config["symbol"] = symbol
                    subscriptions.append(config)
            
            return subscriptions
        except Exception as e:
            logger.error(f"ì „ì²´ êµ¬ë… ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    async def get_status(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ì‹¬ë³¼ ìƒíƒœ ì¡°íšŒ"""
        try:
            key = f"status:{symbol}"
            value = await self.redis.get(key)
            if value:
                return json.loads(value)
            return None
        except Exception as e:
            logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨ - {symbol}: {e}")
            return None
    
    async def get_metrics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        try:
            metrics = {}
            
            # í ê¸¸ì´ í™•ì¸
            metrics["queue_length"] = await self.redis.llen("candle_data_queue")
            metrics["dlq_length"] = await self.redis.llen("dead_letter_queue")
            
            # í”„ë¡œì„¸ì„œ ë©”íŠ¸ë¦­
            processor_metrics = await self.redis.get("processor_metrics")
            if processor_metrics:
                metrics.update(json.loads(processor_metrics))
            
            # í™œì„± êµ¬ë… ìˆ˜
            subscription_keys = await self.redis.keys("subscription:*")
            metrics["active_subscriptions"] = len(subscription_keys)
            
            return metrics
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

# ì „ì—­ Redis ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
redis_manager = RedisManager()
```

#### app/api/models.py
```python
# services/gateway/app/api/models.py
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any
from datetime import datetime
from enum import Enum

class SubscriptionRequest(BaseModel):
    symbols: List[str] = Field(..., min_items=1, max_items=50, description="êµ¬ë…í•  ì‹¬ë³¼ ëª©ë¡")
    timeframes: List[str] = Field(..., min_items=1, max_items=10, description="ì‹œê°„í”„ë ˆì„ ëª©ë¡")
    webhook_url: Optional[str] = Field(None, description="ì›¹í›… URL (ì„ íƒì‚¬í•­)")
    
    @validator('symbols')
    def validate_symbols(cls, v):
        for symbol in v:
            if not symbol or len(symbol.strip()) == 0:
                raise ValueError("ë¹ˆ ì‹¬ë³¼ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            if not symbol.replace('-', '').replace('_', '').isalnum():
                raise ValueError(f"ì˜ëª»ëœ ì‹¬ë³¼ í˜•ì‹: {symbol}")
        return [s.strip().upper() for s in v]
    
    @validator('timeframes')
    def validate_timeframes(cls, v):
        valid_timeframes = {'1m', '3m', '5m', '15m', '30m', '1H', '2H', '4H', '6H', '12H', '1D', '1W', '1M'}
        for tf in v:
            if tf not in valid_timeframes:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„í”„ë ˆì„: {tf}")
        return v

class SubscriptionResponse(BaseModel):
    status: str
    message: str
    symbols: List[str]
    subscription_id: Optional[str] = None
    created_at: datetime

class UnsubscribeResponse(BaseModel):
    status: str
    message: str
    symbol: str
    stopped_at: datetime

class SymbolStatus(BaseModel):
    symbol: str
    status: str
    last_update: datetime
    timeframes: List[str]
    statistics: Optional[Dict[str, Any]] = None
    connection_info: Optional[Dict[str, Any]] = None

class CandleData(BaseModel):
    timestamp: datetime
    open: float = Field(alias="open_price")
    high: float = Field(alias="high_price") 
    low: float = Field(alias="low_price")
    close: float = Field(alias="close_price")
    volume: float
    volume_currency: Optional[float] = None
    confirm: bool = False
    trade_count: Optional[int] = None
    vwap: Optional[float] = None

class CandleDataResponse(BaseModel):
    symbol: str
    timeframe: str
    count: int
    data: List[CandleData]
    pagination: Optional[Dict[str, Any]] = None

class SystemStatus(BaseModel):
    system_status: str
    timestamp: datetime
    services: Dict[str, Any]
    metrics: Dict[str, Any]
    symbols: List[Dict[str, Any]]

class HealthResponse(BaseModel):
    status: str
    timestamp: datetime
    version: str
    uptime_seconds: Optional[int] = None
    checks: Dict[str, str]
    errors: Optional[List[str]] = None

class ErrorResponse(BaseModel):
    status: str = "error"
    error_code: str
    message: str
    details: Optional[Dict[str, Any]] = None
    timestamp: datetime
    request_id: Optional[str] = None

class StatisticsResponse(BaseModel):
    symbol: str
    period: str
    timeframe: str
    statistics: Dict[str, Any]

class MarketOverviewResponse(BaseModel):
    timestamp: datetime
    total_symbols: int
    market_summary: List[Dict[str, Any]]
    system_metrics: Dict[str, Any]

class SortOrder(str, Enum):
    ASC = "asc"
    DESC = "desc"

class QueryParams(BaseModel):
    limit: int = Field(default=100, ge=1, le=1000, description="ì¡°íšŒí•  ë ˆì½”ë“œ ìˆ˜")
    start_time: Optional[datetime] = Field(None, description="ì‹œì‘ ì‹œê°„")
    end_time: Optional[datetime] = Field(None, description="ì¢…ë£Œ ì‹œê°„")
    sort: SortOrder = Field(default=SortOrder.DESC, description="ì •ë ¬ ìˆœì„œ")
```

#### app/api/routes.py
```python
# services/gateway/app/api/routes.py
from fastapi import APIRouter, HTTPException, Depends, Query, Path, status
from fastapi.responses import PlainTextResponse
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
import uuid
import logging

from ..core.database import db_manager
from ..utils.redis_client import redis_manager
from .models import *

logger = logging.getLogger(__name__)
router = APIRouter()

# ì˜ì¡´ì„± í•¨ìˆ˜ë“¤
async def get_db():
    return db_manager

async def get_redis():
    return redis_manager

def generate_request_id():
    return str(uuid.uuid4())[:8]

# êµ¬ë… ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@router.post("/subscribe", response_model=SubscriptionResponse, status_code=status.HTTP_201_CREATED)
async def subscribe_to_symbols(
    request: SubscriptionRequest,
    db=Depends(get_db),
    redis=Depends(get_redis)
):
    """ì‹¬ë³¼ê³¼ ì‹œê°„í”„ë ˆì„ êµ¬ë… ì‹œì‘"""
    request_id = generate_request_id()
    
    try:
        # ì‹¬ë³¼ ìœ íš¨ì„± ê²€ì‚¬
        valid_symbols = await db.get_symbols(active_only=True)
        valid_symbol_names = {s['symbol'] for s in valid_symbols}
        
        invalid_symbols = [s for s in request.symbols if s not in valid_symbol_names]
        if invalid_symbols:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "error_code": "INVALID_SYMBOLS",
                    "message": "ì˜ëª»ëœ ì‹¬ë³¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤",
                    "invalid_symbols": invalid_symbols,
                    "request_id": request_id
                }
            )
        
        # ì‹œê°„í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬
        valid_timeframes = await db.get_timeframes(active_only=True)
        valid_tf_names = {tf['name'] for tf in valid_timeframes}
        
        invalid_timeframes = [tf for tf in request.timeframes if tf not in valid_tf_names]
        if invalid_timeframes:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "error_code": "INVALID_TIMEFRAMES",
                    "message": "ì˜ëª»ëœ ì‹œê°„í”„ë ˆì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤",
                    "invalid_timeframes": invalid_timeframes,
                    "request_id": request_id
                }
            )
        
        # êµ¬ë… ì„¤ì • ìƒì„±
        subscription_config = {
            "action": "subscribe",
            "symbols": request.symbols,
            "timeframes": request.timeframes,
            "webhook_url": request.webhook_url,
            "created_at": datetime.utcnow().isoformat(),
            "request_id": request_id
        }
        
        # ê° ì‹¬ë³¼ë³„ë¡œ êµ¬ë… ì„¤ì • ì €ì¥ ë° ì‹ í˜¸ ë°œì†¡
        for symbol in request.symbols:
            await redis.set_subscription(symbol, subscription_config)
            await redis.publish_subscription(symbol, subscription_config)
        
        logger.info(f"êµ¬ë… ìƒì„± ì™„ë£Œ: {request.symbols} - {request_id}")
        
        return SubscriptionResponse(
            status="success",
            message=f"Subscribed to {len(request.symbols)} symbols",
            symbols=request.symbols,
            subscription_id=request_id,
            created_at=datetime.utcnow()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"êµ¬ë… ìƒì„± ì‹¤íŒ¨: {e} - {request_id}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "SUBSCRIPTION_FAILED",
                "message": "êµ¬ë… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "request_id": request_id
            }
        )

@router.delete("/subscribe/{symbol}", response_model=UnsubscribeResponse)
async def unsubscribe_from_symbol(
    symbol: str = Path(..., description="êµ¬ë… ì·¨ì†Œí•  ì‹¬ë³¼"),
    redis=Depends(get_redis)
):
    """íŠ¹ì • ì‹¬ë³¼ì˜ êµ¬ë… ì·¨ì†Œ"""
    request_id = generate_request_id()
    
    try:
        # ê¸°ì¡´ êµ¬ë… í™•ì¸
        existing_subscription = await redis.get_subscription(symbol)
        if not existing_subscription:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error_code": "SUBSCRIPTION_NOT_FOUND",
                    "message": f"ì‹¬ë³¼ {symbol}ì˜ êµ¬ë…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "request_id": request_id
                }
            )
        
        # êµ¬ë… ì‚­ì œ
        await redis.delete_subscription(symbol)
        
        logger.info(f"êµ¬ë… ì·¨ì†Œ ì™„ë£Œ: {symbol} - {request_id}")
        
        return UnsubscribeResponse(
            status="success",
            message=f"Unsubscribed from {symbol}",
            symbol=symbol,
            stopped_at=datetime.utcnow()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"êµ¬ë… ì·¨ì†Œ ì‹¤íŒ¨: {e} - {request_id}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "UNSUBSCRIBE_FAILED",
                "message": "êµ¬ë… ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "request_id": request_id
            }
        )

@router.get("/subscriptions")
async def get_all_subscriptions(redis=Depends(get_redis)):
    """í˜„ì¬ í™œì„± êµ¬ë… ëª©ë¡ ì¡°íšŒ"""
    try:
        subscriptions = await redis.get_all_subscriptions()
        
        # ê° êµ¬ë…ì˜ ìƒíƒœ ì •ë³´ ì¶”ê°€
        for sub in subscriptions:
            symbol = sub.get("symbol")
            if symbol:
                status_info = await redis.get_status(symbol)
                if status_info:
                    sub.update({
                        "status": status_info.get("status", "unknown"),
                        "last_message": status_info.get("last_update")
                    })
        
        return {
            "status": "success",
            "total": len(subscriptions),
            "subscriptions": subscriptions
        }
        
    except Exception as e:
        logger.error(f"êµ¬ë… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "SUBSCRIPTIONS_QUERY_FAILED",
                "message": "êµ¬ë… ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            }
        )

# ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸
@router.get("/status/{symbol}", response_model=SymbolStatus)
async def get_symbol_status(
    symbol: str = Path(..., description="ì¡°íšŒí•  ì‹¬ë³¼"),
    redis=Depends(get_redis)
):
    """íŠ¹ì • ì‹¬ë³¼ì˜ ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ"""
    try:
        status_info = await redis.get_status(symbol)
        
        if not status_info:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error_code": "SYMBOL_NOT_FOUND",
                    "message": f"ì‹¬ë³¼ {symbol}ì˜ ìƒíƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }
            )
        
        # êµ¬ë… ì •ë³´ ì¶”ê°€
        subscription_info = await redis.get_subscription(symbol)
        timeframes = subscription_info.get("timeframes", []) if subscription_info else []
        
        return SymbolStatus(
            symbol=symbol,
            status=status_info.get("status", "unknown"),
            last_update=datetime.fromisoformat(status_info.get("last_update")),
            timeframes=timeframes,
            statistics=status_info.get("statistics"),
            connection_info=status_info.get("connection_info")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì‹¬ë³¼ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "STATUS_QUERY_FAILED",
                "message": "ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            }
        )

@router.get("/status", response_model=SystemStatus)
async def get_system_status(
    db=Depends(get_db),
    redis=Depends(get_redis)
):
    """ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        db_healthy = await db.health_check()
        redis_healthy = await redis.health_check()
        
        services = {
            "gateway": "healthy",
            "database": "healthy" if db_healthy else "unhealthy",
            "redis": "healthy" if redis_healthy else "unhealthy"
        }
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = await redis.get_metrics()
        
        # ì‹¬ë³¼ë³„ ìƒíƒœ ìˆ˜ì§‘
        subscriptions = await redis.get_all_subscriptions()
        symbol_statuses = []
        
        for sub in subscriptions:
            symbol = sub.get("symbol")
            if symbol:
                status_info = await redis.get_status(symbol)
                if status_info:
                    symbol_statuses.append({
                        "symbol": symbol,
                        "status": status_info.get("status", "unknown"),
                        "last_message": status_info.get("last_update")
                    })
        
        # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
        system_status = "healthy"
        if not db_healthy or not redis_healthy:
            system_status = "unhealthy"
        elif len([s for s in symbol_statuses if s["status"] != "connected"]) > 0:
            system_status = "degraded"
        
        return SystemStatus(
            system_status=system_status,
            timestamp=datetime.utcnow(),
            services=services,
            metrics=metrics,
            symbols=symbol_statuses
        )
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "SYSTEM_STATUS_FAILED",
                "message": "ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            }
        )

# ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
@router.get("/data/{symbol}/{timeframe}", response_model=CandleDataResponse)
async def get_candle_data(
    symbol: str = Path(..., description="ì¡°íšŒí•  ì‹¬ë³¼"),
    timeframe: str = Path(..., description="ì‹œê°„í”„ë ˆì„"),
    limit: int = Query(default=100, ge=1, le=1000, description="ì¡°íšŒí•  ë ˆì½”ë“œ ìˆ˜"),
    start_time: Optional[datetime] = Query(None, description="ì‹œì‘ ì‹œê°„"),
    end_time: Optional[datetime] = Query(None, description="ì¢…ë£Œ ì‹œê°„"),
    sort: SortOrder = Query(default=SortOrder.DESC, description="ì •ë ¬ ìˆœì„œ"),
    db=Depends(get_db)
):
    """íŠ¹ì • ì‹¬ë³¼ê³¼ ì‹œê°„í”„ë ˆì„ì˜ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ì‹¬ë³¼ê³¼ ì‹œê°„í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬ëŠ” DB ì¿¼ë¦¬ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬ë¨
        raw_data = await db.get_candle_data(symbol, timeframe, limit, start_time, end_time)
        
        if not raw_data:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error_code": "NO_DATA_FOUND",
                    "message": f"{symbol} {timeframe} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }
            )
        
        # ë°ì´í„° ì •ë ¬ (í•„ìš”ì‹œ)
        if sort == SortOrder.ASC:
            raw_data = list(reversed(raw_data))
        
        # ì‘ë‹µ ëª¨ë¸ë¡œ ë³€í™˜
        candles = []
        for row in raw_data:
            candles.append(CandleData(
                timestamp=row['timestamp'],
                open_price=float(row['open_price']),
                high_price=float(row['high_price']),
                low_price=float(row['low_price']),
                close_price=float(row['close_price']),
                volume=float(row['volume']),
                volume_currency=float(row['volume_currency']) if row['volume_currency'] else None,
                confirm=row['confirm'],
                trade_count=row['trade_count'],
                vwap=float(row['vwap']) if row['vwap'] else None
            ))
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´
        pagination = None
        if len(candles) == limit:
            last_timestamp = candles[-1].timestamp
            pagination = {
                "has_more": True,
                "next_timestamp": last_timestamp.isoformat()
            }
        
        return CandleDataResponse(
            symbol=symbol,
            timeframe=timeframe,
            count=len(candles),
            data=candles,
            pagination=pagination
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìº”ë“¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error_code": "DATA_QUERY_FAILED",
                "message": "ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            }
        )

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@router.get("/health", response_model=HealthResponse)
async def health_check(
    db=Depends(get_db),
    redis=Depends(get_redis)
):
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬"""
    start_time = datetime.utcnow()
    
    checks = {}
    errors = []
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬
    try:
        db_healthy = await db.health_check()
        checks["database"] = "healthy" if db_healthy else "unhealthy"
        if not db_healthy:
            errors.append("Database connection failed")
    except Exception as e:
        checks["database"] = "unhealthy"
        errors.append(f"Database error: {str(e)}")
    
    # Redis ì²´í¬
    try:
        redis_healthy = await redis.health_check()
        checks["redis"] = "healthy" if redis_healthy else "unhealthy" 
        if not redis_healthy:
            errors.append("Redis connection failed")
    except Exception as e:
        checks["redis"] = "unhealthy"
        errors.append(f"Redis error: {str(e)}")
    
    # ë©”ì‹œì§€ í ì²´í¬
    try:
        metrics = await redis.get_metrics()
        queue_length = metrics.get("queue_length", 0)
        dlq_length = metrics.get("dlq_length", 0)
        
        if queue_length > 50000:  # ë†’ì€ ì„ê³„ê°’
            checks["message_queue"] = "degraded"
            errors.append(f"High queue length: {queue_length}")
        elif dlq_length > 1000:  # DLQ ì„ê³„ê°’
            checks["message_queue"] = "degraded"
            errors.append(f"High DLQ length: {dlq_length}")
        else:
            checks["message_queue"] = "healthy"
    except Exception as e:
        checks["message_queue"] = "unhealthy"
        errors.append(f"Queue check error: {str(e)}")
    
    # ì „ì²´ ìƒíƒœ ê²°ì •
    overall_status = "healthy"
    if any(status == "unhealthy" for status in checks.values()):
        overall_status = "unhealthy"
    elif any(status == "degraded" for status in checks.values()):
        overall_status = "degraded"
    
    response_status = status.HTTP_200_OK if overall_status == "healthy" else status.HTTP_503_SERVICE_UNAVAILABLE
    
    return HealthResponse(
        status=overall_status,
        timestamp=datetime.utcnow(),
        version="1.0.0",
        uptime_seconds=None,  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œì‘ ì‹œê°„ ì¶”ì 
        checks=checks,
        errors=errors if errors else None
    )

@router.get("/metrics", response_class=PlainTextResponse)
async def get_prometheus_metrics(redis=Depends(get_redis)):
    """Prometheus í˜•ì‹ì˜ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        metrics = await redis.get_metrics()
        
        prometheus_metrics = []
        
        # í ê¸¸ì´ ë©”íŠ¸ë¦­
        queue_length = metrics.get("queue_length", 0)
        dlq_length = metrics.get("dlq_length", 0)
        
        prometheus_metrics.extend([
            "# HELP okx_queue_length Current queue length",
            "# TYPE okx_queue_length gauge",
            f'okx_queue_length{{queue="candle_data"}} {queue_length}',
            f'okx_queue_length{{queue="dead_letter"}} {dlq_length}',
            "",
            "# HELP okx_active_subscriptions Number of active subscriptions",
            "# TYPE okx_active_subscriptions gauge",
            f'okx_active_subscriptions {metrics.get("active_subscriptions", 0)}',
        ])
        
        return "\n".join(prometheus_metrics)
        
    except Exception as e:
        logger.error(f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return "# Error retrieving metrics"
```

#### main.py
```python
# services/gateway/main.py
import asyncio
import logging
import signal
import sys
from contextlib import asynccontextmanager

import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from prometheus_client import make_asgi_app
import structlog

from app.core.config import settings
from app.core.database import db_manager
from app.utils.redis_client import redis_manager
from app.api.routes import router as api_router
from app.api.models import ErrorResponse

# ë¡œê¹… ì„¤ì •
def setup_logging():
    if settings.log_format == "json":
        structlog.configure(
            processors=[
                structlog.stdlib.filter_by_level,
                structlog.stdlib.add_logger_name,
                structlog.stdlib.add_log_level,
                structlog.stdlib.PositionalArgumentsFormatter(),
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                structlog.processors.JSONRenderer()
            ],
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            wrapper_class=structlog.stdlib.BoundLogger,
            cache_logger_on_first_use=True,
        )
    
    logging.basicConfig(
        level=getattr(logging, settings.log_level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

setup_logging()
logger = logging.getLogger(__name__)

# ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ OKX Gateway API ì‹œì‘ ì¤‘...")
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”
        await db_manager.initialize()
        
        # Redis ì—°ê²° ì´ˆê¸°í™”
        await redis_manager.initialize()
        
        logger.info("âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
    
    yield
    
    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ›‘ OKX Gateway API ì¢…ë£Œ ì¤‘...")
    
    try:
        await redis_manager.close()
        await db_manager.close()
        logger.info("âœ… ëª¨ë“  ì—°ê²° ì¢…ë£Œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì¢…ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title=settings.app_name,
    version=settings.app_version,
    description="OKX ì‹¤ì‹œê°„ ìº”ë“¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ Gateway API",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=settings.cors_methods,
    allow_headers=settings.cors_headers,
)

# ê¸€ë¡œë²Œ ì˜ˆì™¸ ì²˜ë¦¬ê¸°
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content=exc.detail if isinstance(exc.detail, dict) else {
            "error_code": "HTTP_ERROR",
            "message": str(exc.detail),
            "timestamp": structlog.get_logger().info("timestamp")
        }
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "ìš”ì²­ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤",
            "details": exc.errors(),
            "timestamp": structlog.get_logger().info("timestamp")
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "timestamp": structlog.get_logger().info("timestamp")
        }
    )

# API ë¼ìš°í„° ë“±ë¡
app.include_router(
    api_router,
    prefix=settings.api_v1_prefix,
    tags=["OKX Trading API"]
)

# ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/", tags=["Root"])
async def root():
    return {
        "message": "OKX Trading System Gateway API",
        "version": settings.app_version,
        "environment": settings.environment,
        "docs_url": "/docs"
    }

# Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ (ë³„ë„ í¬íŠ¸)
if settings.metrics_enabled:
    metrics_app = make_asgi_app()
    app.mount("/metrics", metrics_app)

# í”„ë¡œë•ì…˜ì—ì„œ ì‹¤í–‰ë  ë•Œì˜ ì‹ í˜¸ ì²˜ë¦¬
def signal_handler(signum, frame):
    logger.info(f"ì‹ í˜¸ {signum} ìˆ˜ì‹ , ì •ìƒ ì¢…ë£Œ ì¤‘...")
    sys.exit(0)

if __name__ == "__main__":
    # ê°œë°œ í™˜ê²½ì—ì„œì˜ ì‹¤í–‰
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    uvicorn.run(
        "main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug,
        workers=settings.workers if not settings.debug else 1,
        log_level=settings.log_level.lower()
    )
```

#### Dockerfile
```dockerfile
# services/gateway/Dockerfile
FROM python:3.11-slim

# ë©”íƒ€ë°ì´í„°
LABEL maintainer="OKX Trading System"
LABEL version="1.0.0"
LABEL description="OKX Trading Gateway API Service"

# í™˜ê²½ ë³€ìˆ˜
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# ë¹„root ì‚¬ìš©ì ìƒì„±
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app
USER appuser

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000 8080

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["python", "main.py"]
```

### 2. Data Collector Service êµ¬í˜„

#### app/core/config.py
```python
# services/collector/app/core/config.py
from pydantic_settings import BaseSettings
from typing import Optional, List
import os

class Settings(BaseSettings):
    # ì„œë¹„ìŠ¤ ì„¤ì •
    service_name: str = "OKX Data Collector"
    service_version: str = "1.0.0"
    environment: str = "development"
    debug: bool = False
    
    # OKX API ì„¤ì •
    okx_api_key: str = ""
    okx_secret_key: str = ""
    okx_passphrase: str = ""
    okx_websocket_url: str = "wss://ws.okx.com:8443/ws/v5/public"
    okx_rest_api_url: str = "https://www.okx.com/api/v5"
    
    # Redis ì„¤ì •
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    redis_password: Optional[str] = None
    redis_max_connections: int = 50
    
    # WebSocket ì„¤ì •
    websocket_ping_interval: int = 20
    websocket_ping_timeout: int = 10
    websocket_close_timeout: int = 10
    
    # ì¬ì—°ê²° ì„¤ì •
    initial_reconnect_delay: int = 5
    max_reconnect_delay: int = 300
    reconnect_backoff_factor: float = 1.5
    max_reconnect_attempts: int = -1  # -1ì€ ë¬´ì œí•œ
    
    # ë©”ì‹œì§€ ì²˜ë¦¬ ì„¤ì •
    message_queue_name: str = "candle_data_queue"
    dead_letter_queue_name: str = "dead_letter_queue"
    message_timeout: int = 30
    
    # ì‹¬ë³¼ ë° ì‹œê°„í”„ë ˆì„ ì„¤ì •
    symbol: str = "BTC-USDT"  # ê°œë³„ ì»¬ë ‰í„°ë‹¹ í•˜ë‚˜ì˜ ì‹¬ë³¼
    default_timeframes: List[str] = ["1m", "5m", "15m", "1H", "1D"]
    
    # ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_format: str = "json"
    
    # ë©”íŠ¸ë¦­ ì„¤ì •
    metrics_enabled: bool = True
    metrics_update_interval: int = 30
    
    @property
    def redis_url(self) -> str:
        if self.redis_password:
            return f"redis://:{self.redis_password}@{self.redis_host}:{self.redis_port}/{self.redis_db}"
        return f"redis://{self.redis_host}:{self.redis_port}/{self.redis_db}"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

#### app/websocket/client.py
```python
# services/collector/app/websocket/client.py
import asyncio
import json
import logging
import websockets
import hmac
import hashlib
import base64
from datetime import datetime
from typing import Dict, List, Optional, Callable
import redis.asyncio as redis

from ..core.config import settings

logger = logging.getLogger(__name__)

class OKXWebSocketClient:
    def __init__(self, symbol: str):
        self.symbol = symbol
        self.websocket: Optional[websockets.WebSocketServerProtocol] = None
        self.redis_client: Optional[redis.Redis] = None
        self.is_running = False
        self.is_connected = False
        
        # ì¬ì—°ê²° ì„¤ì •
        self.reconnect_delay = settings.initial_reconnect_delay
        self.reconnect_attempts = 0
        
        # êµ¬ë… ìƒíƒœ
        self.current_timeframes: List[str] = []
        self.subscription_id: Optional[str] = None
        
        # í†µê³„
        self.stats = {
            "messages_received": 0,
            "messages_processed": 0,
            "messages_failed": 0,
            "last_message_time": None,
            "connection_start_time": None,
            "reconnect_count": 0
        }
    
    async def initialize(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # Redis ì—°ê²° ì´ˆê¸°í™”
            self.redis_client = await redis.from_url(
                settings.redis_url,
                max_connections=settings.redis_max_connections,
                decode_responses=True
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.redis_client.ping()
            logger.info(f"Redis ì—°ê²° ì´ˆê¸°í™” ì™„ë£Œ: {self.symbol}")
            
            # êµ¬ë… ìš”ì²­ ë¦¬ìŠ¤ë„ˆ ì‹œì‘
            asyncio.create_task(self.listen_for_subscriptions())
            
        except Exception as e:
            logger.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def listen_for_subscriptions(self):
        """Gatewayë¡œë¶€í„° êµ¬ë… ìš”ì²­ ìˆ˜ì‹ """
        pubsub = self.redis_client.pubsub()
        channel = f"collector:{self.symbol}"
        
        try:
            await pubsub.subscribe(channel)
            logger.info(f"êµ¬ë… ì±„ë„ ë¦¬ìŠ¤ë‹ ì‹œì‘: {channel}")
            
            async for message in pubsub.listen():
                if message['type'] == 'message':
                    try:
                        config = json.loads(message['data'])
                        action = config.get('action')
                        
                        if action == 'subscribe':
                            await self.handle_subscribe_request(config)
                        elif action == 'unsubscribe':
                            await self.handle_unsubscribe_request()
                            
                    except Exception as e:
                        logger.error(f"êµ¬ë… ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        
        except Exception as e:
            logger.error(f"êµ¬ë… ë¦¬ìŠ¤ë„ˆ ì˜¤ë¥˜: {e}")
            # ì¬ì‹œì‘ ë¡œì§
            await asyncio.sleep(5)
            asyncio.create_task(self.listen_for_subscriptions())
    
    async def handle_subscribe_request(self, config: Dict):
        """êµ¬ë… ìš”ì²­ ì²˜ë¦¬"""
        try:
            symbols = config.get('symbols', [])
            if self.symbol not in symbols:
                return
            
            new_timeframes = config.get('timeframes', settings.default_timeframes)
            self.subscription_id = config.get('request_id')
            
            # ì´ë¯¸ ì—°ê²°ë˜ì–´ ìˆê³  ê°™ì€ ì‹œê°„í”„ë ˆì„ì´ë©´ ë¬´ì‹œ
            if (self.is_connected and 
                set(new_timeframes) == set(self.current_timeframes)):
                logger.info(f"ë™ì¼í•œ êµ¬ë… ìš”ì²­ ë¬´ì‹œ: {self.symbol}")
                return
            
            # ìƒˆë¡œìš´ êµ¬ë… ì‹œì‘
            self.current_timeframes = new_timeframes
            
            if not self.is_running:
                self.is_running = True
                asyncio.create_task(self.start_connection_loop())
                
            logger.info(f"êµ¬ë… ì‹œì‘: {self.symbol} - {new_timeframes}")
            
        except Exception as e:
            logger.error(f"êµ¬ë… ìš”ì²­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def handle_unsubscribe_request(self):
        """êµ¬ë… ì·¨ì†Œ ì²˜ë¦¬"""
        try:
            self.is_running = False
            
            if self.websocket and not self.websocket.closed:
                await self.websocket.close()
            
            await self.update_status("disconnected", "unsubscribed by request")
            logger.info(f"êµ¬ë… ì·¨ì†Œ ì™„ë£Œ: {self.symbol}")
            
        except Exception as e:
            logger.error(f"êµ¬ë… ì·¨ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def start_connection_loop(self):
        """WebSocket ì—°ê²° ë£¨í”„"""
        while self.is_running:
            try:
                await self.connect_and_collect()
                
            except Exception as e:
                logger.error(f"ì—°ê²° ì˜¤ë¥˜: {self.symbol} - {e}")
                await self.handle_connection_error()
            
            if self.is_running:
                await asyncio.sleep(self.reconnect_delay)
    
    async def connect_and_collect(self):
        """WebSocket ì—°ê²° ë° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            logger.info(f"WebSocket ì—°ê²° ì‹œì‘: {self.symbol}")
            
            async with websockets.connect(
                settings.okx_websocket_url,
                ping_interval=settings.websocket_ping_interval,
                ping_timeout=settings.websocket_ping_timeout,
                close_timeout=settings.websocket_close_timeout
            ) as websocket:
                
                self.websocket = websocket
                self.is_connected = True
                self.stats["connection_start_time"] = datetime.utcnow().isoformat()
                
                # êµ¬ë… ë©”ì‹œì§€ ì „ì†¡
                await self.send_subscription_message()
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                await self.update_status("connected")
                
                # ì¬ì—°ê²° ì„¤ì • ì´ˆê¸°í™”
                self.reconnect_delay = settings.initial_reconnect_delay
                self.reconnect_attempts = 0
                
                logger.info(f"WebSocket ì—°ê²° ì„±ê³µ: {self.symbol}")
                
                # ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
                async for message in websocket:
                    await self.process_message(json.loads(message))
                    
        except websockets.exceptions.ConnectionClosed as e:
            logger.warning(f"WebSocket ì—°ê²° ì¢…ë£Œ: {self.symbol} - {e}")
            self.is_connected = False
            raise
            
        except Exception as e:
            logger.error(f"WebSocket ì—°ê²° ì‹¤íŒ¨: {self.symbol} - {e}")
            self.is_connected = False
            raise
    
    async def send_subscription_message(self):
        """êµ¬ë… ë©”ì‹œì§€ ì „ì†¡"""
        try:
            subscription_args = []
            for timeframe in self.current_timeframes:
                subscription_args.append({
                    "channel": f"candle{timeframe}",
                    "instId": self.symbol
                })
            
            subscribe_msg = {
                "op": "subscribe",
                "args": subscription_args
            }
            
            await self.websocket.send(json.dumps(subscribe_msg))
            logger.info(f"êµ¬ë… ë©”ì‹œì§€ ì „ì†¡: {self.symbol} - {self.current_timeframes}")
            
        except Exception as e:
            logger.error(f"êµ¬ë… ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            raise
    
    async def process_message(self, data: Dict):
        """ìˆ˜ì‹ ëœ ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            self.stats["messages_received"] += 1
            self.stats["last_message_time"] = datetime.utcnow().isoformat()
            
            # ë©”ì‹œì§€ íƒ€ì… í™•ì¸
            if 'event' in data:
                await self.handle_event_message(data)
                return
            
            if 'data' not in data:
                return
            
            # ìº”ë“¤ ë°ì´í„° ì²˜ë¦¬
            for candle_data in data['data']:
                await self.process_candle_data(candle_data, data.get('arg', {}))
                
            self.stats["messages_processed"] += 1
            
        except Exception as e:
            self.stats["messages_failed"] += 1
            logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e} - {data}")
    
    async def handle_event_message(self, data: Dict):
        """ì´ë²¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬"""
        event = data.get('event')
        
        if event == 'subscribe':
            if data.get('code') == '0':
                logger.info(f"êµ¬ë… ì„±ê³µ: {self.symbol}")
            else:
                logger.error(f"êµ¬ë… ì‹¤íŒ¨: {data}")
                
        elif event == 'error':
            logger.error(f"ì„œë²„ ì˜¤ë¥˜: {data}")
    
    async def process_candle_data(self, candle_data: List, channel_info: Dict):
        """ìº”ë“¤ ë°ì´í„° ì²˜ë¦¬ ë° Redis í ì „ì†¡"""
        try:
            # OKX ìº”ë“¤ ë°ì´í„° í˜•ì‹:
            # [timestamp, open, high, low, close, volume, volume_currency, confirm, trade_count]
            
            timeframe = channel_info.get('channel', '').replace('candle', '')
            
            processed_data = {
                "symbol": self.symbol,
                "timeframe": timeframe,
                "timestamp": int(candle_data[0]),
                "open": float(candle_data[1]),
                "high": float(candle_data[2]),
                "low": float(candle_data[3]),
                "close": float(candle_data[4]),
                "volume": float(candle_data[5]),
                "volume_currency": float(candle_data[6]),
                "confirm": candle_data[8] == "1",
                "trade_count": int(candle_data[7]) if len(candle_data) > 7 else 0,
                "received_at": datetime.utcnow().isoformat(),
                "collector_id": self.subscription_id,
                "raw_data": candle_data
            }
            
            # Redis íì— ì „ì†¡
            await self.redis_client.lpush(
                settings.message_queue_name,
                json.dumps(processed_data)
            )
            
            # ë””ë²„ê·¸ ë¡œê·¸ (ê°œë°œí™˜ê²½ì—ì„œë§Œ)
            if settings.debug:
                logger.debug(f"ìº”ë“¤ ë°ì´í„° í ì „ì†¡: {self.symbol} {timeframe} {processed_data['close']}")
            
        except Exception as e:
            logger.error(f"ìº”ë“¤ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    async def handle_connection_error(self):
        """ì—°ê²° ì˜¤ë¥˜ ì²˜ë¦¬"""
        self.is_connected = False
        self.reconnect_attempts += 1
        self.stats["reconnect_count"] += 1
        
        # ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©
        self.reconnect_delay = min(
            self.reconnect_delay * settings.reconnect_backoff_factor,
            settings.max_reconnect_delay
        )
        
        await self.update_status(
            "disconnected", 
            f"reconnection attempt {self.reconnect_attempts}"
        )
        
        logger.warning(
            f"ì¬ì—°ê²° ëŒ€ê¸°: {self.symbol} - "
            f"ì‹œë„ {self.reconnect_attempts}, ì§€ì—° {self.reconnect_delay}ì´ˆ"
        )
    
    async def update_status(self, status: str, message: str = ""):
        """ìƒíƒœ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            status_data = {
                "symbol": self.symbol,
                "status": status,
                "message": message,
                "last_update": datetime.utcnow().isoformat(),
                "timeframes": self.current_timeframes,
                "subscription_id": self.subscription_id,
                "statistics": self.stats.copy(),
                "connection_info": {
                    "websocket_connected": self.is_connected,
                    "reconnect_attempts": self.reconnect_attempts,
                    "current_delay": self.reconnect_delay
                }
            }
            
            await self.redis_client.setex(
                f"status:{self.symbol}",
                300,  # 5ë¶„ TTL
                json.dumps(status_data)
            )
            
        except Exception as e:
            logger.error(f"ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ: {self.symbol}")
        
        self.is_running = False
        
        if self.websocket and not self.websocket.closed:
            await self.websocket.close()
        
        if self.redis_client:
            await self.redis_client.close()
        
        await self.update_status("stopped")
```

#### main.py
```python
# services/collector/main.py
import asyncio
import logging
import signal
import sys
import os

from app.core.config import settings
from app.websocket.client import OKXWebSocketClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, settings.log_level.upper()),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

logger = logging.getLogger(__name__)

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
client: OKXWebSocketClient = None

async def main():
    global client
    
    logger.info(f"ğŸš€ OKX Data Collector ì‹œì‘: {settings.symbol}")
    
    try:
        # WebSocket í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OKXWebSocketClient(settings.symbol)
        await client.initialize()
        
        logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {settings.symbol}")
        
        # ë¬´í•œ ì‹¤í–‰
        while True:
            await asyncio.sleep(1)
            
    except KeyboardInterrupt:
        logger.info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ìˆ˜ì‹ ")
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise
    finally:
        if client:
            await client.close()
        logger.info("ğŸ›‘ Data Collector ì¢…ë£Œ")

def signal_handler(signum, frame):
    logger.info(f"ì‹ í˜¸ {signum} ìˆ˜ì‹ , ì¢…ë£Œ ì¤‘...")
    if client:
        asyncio.create_task(client.close())
    sys.exit(0)

if __name__ == "__main__":
    # ì‹ í˜¸ ì²˜ë¦¬ ì„¤ì •
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì‹¬ë³¼ í™•ì¸
    symbol = os.getenv('SYMBOL', settings.symbol)
    if symbol != settings.symbol:
        settings.symbol = symbol
    
    logger.info(f"ìˆ˜ì§‘ ëŒ€ìƒ ì‹¬ë³¼: {settings.symbol}")
    
    # ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        sys.exit(1)
```

ì´ ë¬¸ì„œëŠ” OKX ì‹¤ì‹œê°„ ìº”ë“¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œì˜ ì™„ì „í•œ ì½”ë“œ í…œí”Œë¦¿ê³¼ êµ¬í˜„ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. Claude Codeê°€ ì´ í…œí”Œë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ ì¦‰ì‹œ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ ì‹œìŠ¤í…œì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.